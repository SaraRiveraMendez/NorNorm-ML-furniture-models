"""
This type stub file was generated by pyright.
"""

from ultralytics.engine.predictor import BasePredictor

class RTDETRPredictor(BasePredictor):
    """
    RT-DETR (Real-Time Detection Transformer) Predictor extending the BasePredictor class for making predictions.

    This class leverages Vision Transformers to provide real-time object detection while maintaining high accuracy.
    It supports key features like efficient hybrid encoding and IoU-aware query selection.

    Attributes:
        imgsz (int): Image size for inference (must be square and scale-filled).
        args (dict): Argument overrides for the predictor.
        model (torch.nn.Module): The loaded RT-DETR model.
        batch (list): Current batch of processed inputs.

    Methods:
        postprocess: Postprocess raw model predictions to generate bounding boxes and confidence scores.
        pre_transform: Pre-transform input images before feeding them into the model for inference.

    Examples:
        >>> from ultralytics.utils import ASSETS
        >>> from ultralytics.models.rtdetr import RTDETRPredictor
        >>> args = dict(model="rtdetr-l.pt", source=ASSETS)
        >>> predictor = RTDETRPredictor(overrides=args)
        >>> predictor.predict_cli()
    """
    def postprocess(self, preds, img, orig_imgs): # -> list[Any]:
        """
        Postprocess the raw predictions from the model to generate bounding boxes and confidence scores.

        The method filters detections based on confidence and class if specified in `self.args`. It converts
        model predictions to Results objects containing properly scaled bounding boxes.

        Args:
            preds (list | tuple): List of [predictions, extra] from the model, where predictions contain
                bounding boxes and scores.
            img (torch.Tensor): Processed input images with shape (N, 3, H, W).
            orig_imgs (list | torch.Tensor): Original, unprocessed images.

        Returns:
            results (List[Results]): A list of Results objects containing the post-processed bounding boxes,
                confidence scores, and class labels.
        """
        ...
    
    def pre_transform(self, im): # -> list[Dict[str, Any] | ndarray[Any, Any]]:
        """
        Pre-transform input images before feeding them into the model for inference.

        The input images are letterboxed to ensure a square aspect ratio and scale-filled. The size must be square
        (640) and scale_filled.

        Args:
            im (List[np.ndarray]  | torch.Tensor): Input images of shape (N, 3, H, W) for tensor,
                [(H, W, 3) x N] for list.

        Returns:
            (list): List of pre-transformed images ready for model inference.
        """
        ...
    


